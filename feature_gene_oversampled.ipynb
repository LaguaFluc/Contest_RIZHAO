{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "73e03da126b73bfff3642ec5261d56fa25c444ea595de51041687efaa60dda41"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   XINGBIE   AGE  HYZK  ZHIYE  ZHICHEN  ZHIWU  XUELI  DWJJLX  DWSSHY   GRJCJS  \\\n0      1.0  18.0  90.0   90.0    999.0    0.0   99.0   150.0    12.0   1737.0   \n1      2.0  35.0  90.0   90.0    999.0    0.0   99.0   110.0     0.0   4894.0   \n2      1.0  27.0  90.0   90.0    999.0    0.0   99.0   150.0     9.0  10297.0   \n3      1.0  37.0  90.0   90.0    999.0    0.0   99.0   150.0     7.0  10071.5   \n4      2.0  33.0  90.0   90.0    999.0    0.0   99.0   900.0    14.0   2007.0   \n\n   GRZHZT      GRZHYE  GRZHSNJZYE  GRZHDNGJYE   GRYJCE     DKFFE        DKYE  \\\n0     1.0    3223.515     801.310     837.000   312.00  175237.0  154112.935   \n1     1.0   18055.195   53213.220    1065.200   795.84  300237.0  298252.945   \n2     1.0   27426.600   13963.140    7230.020  1444.20  150237.0  147339.130   \n3     1.0  111871.130   99701.265    2271.295  1417.14  350237.0  300653.780   \n4     1.0     237.000   11028.875      35.780   325.50  150237.0  145185.010   \n\n    DKLL  label  \n0  2.708    0.0  \n1  2.979    0.0  \n2  2.708    0.0  \n3  2.708    0.0  \n4  2.708    0.0  \n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "path_train = 'data_file/train-age-oversampled.csv'\n",
    "\n",
    "data_train = pd.read_csv(path_train, header=0)\n",
    "print(data_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(new_combin_li) 21\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "# 连续变量\n",
    "feature_li = ['GRJCJS', 'GRZHYE', 'GRZHSNJZYE', 'GRZHDNGJYE', 'GRYJCE', 'DKFFE', 'DKYE']\n",
    "\n",
    "# 创造新的变量\n",
    "# 使用最简单的方法：1 简单数学计算（主要是连续变量之间\n",
    "def feature_arithmetic(data, f1, f2, operation):\n",
    "    # 连接两个变量，创造新的变量名\n",
    "    new_name = f1 +'_' + operation + '_' + f2\n",
    "    \n",
    "    if operation == 'add':\n",
    "        new_df = data.loc[:, f1] + data.loc[:, f2]\n",
    "    elif operation == 'subtract':\n",
    "        new_df = data.loc[:, f1] - data.loc[:, f2]\n",
    "    elif operation == 'multiply':\n",
    "        new_df = data.loc[:, f1] * data.loc[:, f2]\n",
    "\n",
    "    # 代表  a / b， 前者 / 后者\n",
    "    elif operation == 'divide_ab':\n",
    "        new_df = data.loc[:, f1] / data.loc[:, f2]\n",
    "        new_df.astype(float)\n",
    "    # 代表 b / a， 后者 / 前者\n",
    "    elif operation == 'divide_ba':\n",
    "        new_df = data.loc[:, f2] / data.loc[:, f1]\n",
    "        new_df.astype(float)\n",
    "\n",
    "    return new_name, new_df\n",
    "\n",
    "# TODO：将feature_li默认参数转变成不变的，这里有风险\n",
    "def bin_features(data, feature_li=feature_li):\n",
    "    name_5_operations = ['add', 'subtract', 'multiply', 'divide_ab', 'divide_ba']\n",
    "    # feature_arithmetic_names = []\n",
    "    new_combin_li = list(itertools.combinations(feature_li, 2))\n",
    "    print('len(new_combin_li)', len(new_combin_li)) # for check\n",
    "\n",
    "    # generate feature using basic math operation(four operations)\n",
    "    vocant = []\n",
    "    for f1, f2 in new_combin_li:\n",
    "        for operation in name_5_operations:\n",
    "            vocant.append(feature_arithmetic(data, f1, f2, operation))\n",
    "    \n",
    "    # the number of feature created.\n",
    "    print(len(new_combin_li) * len(name_5_operations)) # for check\n",
    "    \n",
    "    # add new feature to data\n",
    "    for new_name, new_df in vocant:\n",
    "        data[new_name] = new_df\n",
    "\n",
    "    return data  \n",
    "\n",
    "# call the function to generate feature\n",
    "data_feature_bined = bin_features(data_train)\n",
    "\n",
    "# set label in the last column\n",
    "df_label = data_feature_bined['label']\n",
    "data_feature_bined = data_feature_bined.drop('label', axis=1)\n",
    "data_feature_bined['label'] = df_label\n",
    "\n",
    "# write to csv file\n",
    "# also for the correlation matrix in the excel.\n",
    "data_feature_bined.to_csv('data_file/data_train_generation.csv')\n",
    "data_feature_bined.corr().to_excel('data_file/data_train_corr.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "124\nremain features(no categorical) 50\n"
     ]
    }
   ],
   "source": [
    "# categorial variables\n",
    "# using correlation method to remain top 50% variables \n",
    "# that is correlated with label,\n",
    "# ignoring the categorial variables\n",
    "categorial_var = ['XINGBIE', 'AGE', 'HYZK', 'ZHIYE', 'ZHICHEN', 'ZHIWU',\n",
    "'XUELI', 'DWJJLX', 'DWSSHY', 'GRZHZT', 'DKLL', 'label']\n",
    "  \n",
    "\n",
    "def select_top_half_feature(data, categorial_var=categorial_var):\n",
    "    \"\"\"1. 计算变量之间的相关性corr，根据label标签排序\n",
    "    2. 确定需要留下来的特征个数 num_remain\n",
    "    3. 在2中，去掉分类变量的个数 num_remain - len(categorial_var)\n",
    "    4. 去掉分类变量，对剩下变量的相关系数排序(因为在排序的时候考虑分类变量)\n",
    "    5. 找到前面前num_remain - len(categorial_var) 个变量\n",
    "    6. 按照 分类变量 5中的变量 label 的特征顺序，返回一个dataframe\"\"\"\n",
    "    \n",
    "    # 1. corr, label排序\n",
    "    data_corr = data.corr().loc[:, 'label']\n",
    "    print(len(data_corr))\n",
    "\n",
    "    # 2.确定需要留下来的变量个数\n",
    "    num_drop = int(len(data_corr.index) / 2)\n",
    "    num_remain = len(data_corr.index) - num_drop\n",
    "\n",
    "    # 3 算作3 >_<\n",
    "    feature_nocategor = [fea for fea in data_corr.index if fea not in categorial_var]\n",
    "\n",
    "    # 4 按照相关性，对除去分类变量的数据，进行排序\n",
    "    feature_rank_abs = pd.DataFrame(\n",
    "        np.abs(data_corr.loc[feature_nocategor])\n",
    "        ).sort_values(by='label', ascending=False, inplace=False)\n",
    "    print('remain features(no categorical)', num_remain - len(categorial_var))\n",
    "    # 5 除去分类变量，剩下需要的变量\n",
    "    cols = feature_rank_abs.index.tolist()[:num_remain - len(categorial_var)]\n",
    "\n",
    "    # 5 6 将label 放在最后一列（非必要）\n",
    "    categorial_var.remove('label')\n",
    "    feature_need = categorial_var + cols + ['label']\n",
    "    return data.loc[:, feature_need]\n",
    "\n",
    "data_corr_selected = select_top_half_feature(data_feature_bined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"保存数据\n",
    "其实后来看的话，只需要保存相关的特征就好了，后面直接调用这个文件的函数，计算出那些需要留下来的特征\n",
    "避免了过多的文件读写操作\n",
    "index=0 是说不将索引（0, 1, 2, 3...) 写进csv文件中\"\"\"\n",
    "data_corr_selected.to_csv('data_file/data_train_corr_selected.csv', index=0)"
   ]
  }
 ]
}